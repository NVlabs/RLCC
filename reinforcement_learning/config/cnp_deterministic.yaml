env:
  scenarios:
    - 2_to_1
  envs_per_scenario: 8
  history_length: 1
  omnet:
    recv_len: 15  # number of features received from the OMNeT simulator
    size_of_data: 4  # size of float or uint32_t
    simulator_path: ../simulator  # relative to reinforcement_learning dir
    exe_path: ../bin/ccsim_release  # relative to run_path
    config_path: ccsim.ini # relative to run_path
  reward: constrained
  default_port: 5555
  port_increment: 0

training:
  max_timesteps: 1000000
  learning_rate: 0.00025
  gradient_clip: .5
  replay_size: 1000000

agent:
  save_name: ''
  evaluate: False
  agent_type: DETERMINISTIC
  agent_features:
    - action
    - cnp_ratio
#    - relative_buffer_utilization
#    - switch_rate
#    - latency_mean_min_ratio
#    - bandwidth
#    - nack_indicator
#    - rtt_rate_signal
#    - nack_ratio
#    - latency_inflation
#    - requested_rate
  linear_lr_decay: False
  activation_function: relu
  deterministic:
    action_multiplier_dec: 0.2
    action_multiplier_inc: 0.2
    rollout_length: 1024
    architecture:
      - 32
      - 16
    use_lstm: True
    constraint: cnp

logging:
  wandb: False  # Logging using weights and biases
  wandb_run_name: unnamed  # Logging using weights and biases
  min_log_interval: 1024 # The minimum number of iterations before each log occurs
